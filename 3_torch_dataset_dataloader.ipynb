{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7QLMgcBjZ1VZXMiPh6IbK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alifars/torch101/blob/main/torch_dataset_dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o1EZwbpAlx9a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "random.seed(42)\n",
        "\n",
        "X = np.random.randn(100)\n",
        "a, b = 2,3\n",
        "noise = np.random.randn(100)\n",
        "y = a*X + b + noise\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.2)\n",
        "\n",
        "X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor = torch.from_numpy(X_train),torch.from_numpy(X_test),torch.from_numpy(y_train),torch.from_numpy(y_test)"
      ],
      "metadata": {
        "id": "k7Ux_ZvR02Iu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch Dataset and DataLoader\n",
        "\n",
        "why we need a torch dataset?\n",
        "\n",
        "we use it in torch DataLoader later\n",
        "we dont want to load all our dataset to GPU\n"
      ],
      "metadata": {
        "id": "3iQvzawpl2TY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, TensorDataset"
      ],
      "metadata": {
        "id": "GAjoxrIel-D4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, x_tensor, y_tensor):\n",
        "    self.x = x_tensor\n",
        "    self.y = y_tensor\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  def __getitem__(self, index):\n",
        "    return (self.x[index], self.y[index])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lhls0sSmxgPf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = CustomDataset(X_train_tensor, y_train_tensor)\n",
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roRhFy1A0unI",
        "outputId": "6fa73af1-644c-4272-aed7-9a3b7f6543bb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.5645, dtype=torch.float64), tensor(2.7543, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader\n",
        "\n",
        "Untill now we used all datapoint to update the parameters. it's called **Batch gradient descent** . we use toch DataLoader class to slice our data into mini batches\n"
      ],
      "metadata": {
        "id": "JRS7m3Jc7yNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "odmrIeDK7v9W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "_GLvUoNl7vQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size= 16)"
      ],
      "metadata": {
        "id": "t709MoVC1D9T"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XA1GQ5RZ9sIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6Akodg19EwA",
        "outputId": "ee498fbc-0a86-41f0-dd47-ce4283baeafc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([-0.5645,  1.0580, -0.5883, -0.9515, -0.7506, -0.1873, -0.5635,  0.4329,\n",
              "         -0.9426, -0.6079, -1.6980, -0.2633, -0.6687, -1.1391, -1.0051, -0.5724],\n",
              "        dtype=torch.float64),\n",
              " tensor([ 2.7543,  5.2001,  3.1475, -0.3453, -1.7313,  3.5558,  2.1884,  3.4572,\n",
              "         -0.0529,  1.8447, -0.3024,  2.8796,  0.7359,  0.3865, -0.1447,  2.5345],\n",
              "        dtype=torch.float64)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset random split\n"
      ],
      "metadata": {
        "id": "lBhGoEaD9tmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy.sql.visitors import ExtendedInternalTraversal\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "x_tensor, y_tensor = torch.from_numpy(X), torch.from_numpy(y)\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "\n",
        "train_data, val_data = random_split(dataset,[80, 20])\n",
        "train_loader = DataLoader(train_data, batch_size=32)\n",
        "ExtendedInternalTraversal_loader = DataLoader(val_data, batch_size=32)\n"
      ],
      "metadata": {
        "id": "MLsmD3xw9H8R"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "we need anothe inner loop to do evaluation on eval_dataloader. we need to becarefull of these two points:\n",
        "\n",
        "\n",
        "*   torch_no_grad\n",
        "*   model.eval()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rreNCNI1_3vL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HqSSw1yB-az3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
